**Pupil** is an eye tracking hardware and software framework that started as a [thesis project at MIT.](http://willpatera.com/pupil/Kassner_Patera_Pupil_Book.pdf) **Pupil** is a project in active, community driven development.  For noncommercial use, the hardware is accessible, hackable, and affordable. The software is open source and written in Python and C where speed is an issue.<br><br>
Our vision is to create a tool kit for a diverse group of people interested in learning about eye tracking and conducting their eye tracking projects. <br><br>

<h2>Headset</h2>
<table><tr><td width='300px'>
<img src='http://wiki.pupil.googlecode.com/git/images/per_white_faint_570.png' />
</td>
<td>
We have developed a robust head mounted mobile eye tracking device built with modular parts in order to accommodate <a href='http://en.wikipedia.org/wiki/USB_video_device_class'>UVC</a> (most webcams) and some of our own custom built cameras.<br>
<br>
This way you have access to really good hardware for your research and experiments.  Which means that we can concentrate on good design, instead of dealing with logistics and manufacture.  We look forward to <i>seeing</i> your projects, hacks, developments, and ideas for future changes!<br>
<ul><li>Go to <a href='http://www.pupil-labs.com/projects'>pupil-labs.com</a> to purchase a headset and get started with Pupil!<br>
</li></ul><blockquote></td></tr></table>
<h2>Capture Software</h2>
<table><tr><td>
The capture system we have developed enables one to capture eye movements and to record world video and gaze positions for analysis.  In this screen capture the pupil detection component of the capture software is shown.<br>
</blockquote><ul><li>Head over to our <a href='http://github.com/pupil-labs/pupil'>Github page</a> for an intro to the software, source code and user guide.<br>
</td><td>
<wiki:gadget url="http://wiki.pupil.googlecode.com/git/embed_vimeo_eye.xml"  width="300" height="181"/><br>
</li></ul><blockquote></td></tr></table>
<h2>Visualization Software</h2>
<table><tr><td width='400px'>
<a href='http://www.youtube.com/watch?feature=player_embedded&v=P2c4h5d8BEA' target='_blank'><img src='http://img.youtube.com/vi/P2c4h5d8BEA/0.jpg' width='425' height=344 /></a><br>
</td><td>
</td><td>
</td><td>
Once you have recorded some data, it is available in an easy to read format. You can use the <a href='https://github.com/pupil-labs/pupil/wiki/Basic-Workflow#visualize'>Simple Player</a> to view your recording. It can be used to export video segments with pupil position visualizations as overlay. In this screenshot, a transparent red dot indicates the current area of visual attention. Simple Player is simplistic and intended to be modifiable to your specific needs and desires. We wrote it in Python using <a href='http://opencv.org'>opencv</a> libraries. This makes it an ideal prototyping platform for your experiments.  We encourage you to develop your own analyses and visualisation tools!<br>
</td></tr></table></blockquote>

<h2>Discussion Forum</h2>
The main forum for <b>PUPIL</b> discussion is the <a href='http://groups.google.com/group/pupil-discuss'>pupil-discuss</a> group. You can browse discussions online or provide your email address for immediate or digest updates.<br>
<br>
<h2>Pupil in 3D</h2>
<a href='http://code.google.com/p/pupil3d'>Pupil3d</a> uses <b>Pupil</b> for experimental 3D tracking of visual attention using structure from motion. This is a project worthy of its own repo (we think!).<br>
